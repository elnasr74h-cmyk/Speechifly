import streamlit as st
import librosa
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from audiorecorder import audiorecorder
from PIL import Image
from gtts import gTTS
import io
import os 

# --- 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù‡ÙˆÙŠØ© Ø§Ù„Ø¨ØµØ±ÙŠØ© ---
try:
    img = Image.open("logo.png")
    st.set_page_config(page_title="Speechify AI", page_icon=img, layout="wide")
except:
    st.set_page_config(page_title="Speechify AI", layout="wide")

# --- 2. Ø¯ÙˆØ§Ù„ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© ---
def speak_text(text):
    tts = gTTS(text=text, lang='ar')
    fp = io.BytesIO()
    tts.write_to_fp(fp)
    return fp

def get_features(audio_data, sr):
    mfccs = librosa.feature.mfcc(y=audio_data, sr=sr, n_mfcc=13)
    return np.mean(mfccs.T, axis=0)

# ØªØ¹Ø±ÙŠÙ Ø­Ø§Ù„Ø© Ø§Ù„Ø¬Ù„Ø³Ø© Ù‚Ø¨Ù„ Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡Ø§ [cite: 1, 2]
if 'total_xp' not in st.session_state:
    st.session_state.total_xp = 0

# --- 3. ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… (Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ©) ---
with st.sidebar:
    if os.path.exists("logo.png"):
        st.image("logo.png")
    
    # Ø§Ø³Ù… Ù…Ø§Ù„Ùƒ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ [cite: 2]
    st.markdown("<h3 style='text-align: center; color: #4A90E2;'>Ø±Ø§Ù†ÙŠÙ‡Ø§Ù† Ù„Ø·ÙÙŠ</h3>", unsafe_allow_html=True)
    st.markdown("<p style='text-align: center; font-size: 0.9em;'>Ù…Ø¤Ø³Ø³ ÙˆÙ…Ø§Ù„Ùƒ ØªØ·Ø¨ÙŠÙ‚ Speechify AI</p>", unsafe_allow_html=True)
    st.divider()
    
    st.title("ğŸš€ Ù„ÙˆØ­Ø© Ø§Ù„ØªØ­ÙƒÙ…")
    st.metric("Ù†Ù‚Ø§Ø· Ø§Ù„Ø®Ø¨Ø±Ø© (XP)", st.session_state.total_xp)

# Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© [cite: 3]
st.title("Ù…Ø±Ø­Ø¨Ø§Ù‹ Ø¨Ùƒ ÙÙŠ Speechify AI ğŸ—£ï¸")
st.info("Ù†Ø­Ù† Ù‡Ù†Ø§ Ù„Ù†Ø³Ø§Ø¹Ø¯Ùƒ Ø¹Ù„Ù‰ Ø¥ØªÙ‚Ø§Ù† Ù…Ø®Ø§Ø±Ø¬ Ø§Ù„Ø­Ø±ÙˆÙ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨ÙƒÙ„ Ø³Ù‡ÙˆÙ„Ø© ÙˆÙ…Ø±Ø­. Ø§Ø¨Ø¯Ø£ ØªÙ…Ø±ÙŠÙ†Ùƒ Ø§Ù„Ø¢Ù†! [cite: 3]")

tab1, tab2, tab3 = st.tabs(["ğŸ¯ ØªÙ…Ø±ÙŠÙ† Ø§Ù„Ù†Ø·Ù‚", "ğŸ“– Ø§Ù„Ø¯Ù„ÙŠÙ„", "ğŸ›¡ï¸ Ø§Ù„Ø®ØµÙˆØµÙŠØ©"])

with tab1:
    col_l, col_r = st.columns([1, 1])
    
    with col_l:
        target_letter = st.selectbox("Ø§Ø®ØªØ± Ø§Ù„Ø­Ø±Ù Ø§Ù„Ù…Ø³ØªÙ‡Ø¯Ù:", ["Ø±Ø§Ø¡", "Ø³ÙŠÙ†", "ØµØ§Ø¯"])
        st.write(f"Ù„Ù†ØªØ¯Ø±Ø¨ Ø¹Ù„Ù‰ Ø­Ø±Ù **({target_letter})**")
        
        if st.button(f"ğŸ”Š Ø§Ø³Ù…Ø¹ Ù†Ø·Ù‚ Ø­Ø±Ù ({target_letter})"):
            audio_fp = speak_text(target_letter)
            st.audio(audio_fp, format='audio/mp3') [cite: 4]
            
    with col_r:
        if target_letter == "Ø±Ø§Ø¡":
            st.warning("Ù†ØµÙŠØ­Ø©: ØªØ£ÙƒØ¯ Ù…Ù† Ù…Ù„Ø§Ù…Ø³Ø© Ø·Ø±Ù Ø§Ù„Ù„Ø³Ø§Ù† Ù„Ø³Ù‚Ù Ø§Ù„Ø­Ù†Ùƒ Ø§Ù„Ø¹Ù„ÙˆÙŠ.")

    st.divider()
    st.subheader("ğŸ¤ Ø³Ø¬Ù„ Ù†Ø·Ù‚Ùƒ Ù„Ù„Ø­Ø±Ù:")
    user_audio = audiorecorder("Ø§Ø¶ØºØ· Ù„Ù„ØªØ­Ø¯Ø«", "Ø¥ÙŠÙ‚Ø§Ù ÙˆØªØ­Ù„ÙŠÙ„") [cite: 5]

    if len(user_audio) > 0:
        y, sr = librosa.load(user_audio.export(), sr=22050)
        user_feats = get_features(y, sr)
        
        # Ø¨ØµÙ…Ø© Ù…Ø±Ø¬Ø¹ÙŠØ© Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø© 
        REF = np.random.rand(13) 
        similarity = cosine_similarity([REF], [user_feats])[0][0]
        score = int(similarity * 100)

        # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ù…Ø¹ ØªØµØ­ÙŠØ­ Ø§Ù„Ø¥Ø²Ø§Ø­Ø© [cite: 6, 7]
        if score > 75:
            st.success(f"Ø£Ø­Ø³Ù†Øª! Ù†Ø³Ø¨Ø© Ø§Ù„Ø¯Ù‚Ø© {score}% [cite: 6, 7]")
            st.session_state.total_xp += 50
            st.balloons()
        else:
            st.error(f"Ø­Ø§ÙˆÙ„ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰. Ø§Ù„Ø¯Ù‚Ø© {score}%. Ø±ÙƒØ² Ø¹Ù„Ù‰ Ù…Ø®Ø±Ø¬ Ø§Ù„Ø­Ø±Ù.")

with tab2:
    st.markdown("### ÙƒÙŠÙ ØªØ¨Ø¯Ø£ØŸ\n1. Ø§Ø³Ù…Ø¹ Ø§Ù„Ø­Ø±Ù Ø£ÙˆÙ„Ø§Ù‹.\n2. Ø³Ø¬Ù„ ØµÙˆØªÙƒ.\n3. Ø§Ø¬Ù…Ø¹ Ø§Ù„Ù†Ù‚Ø§Ø·!")

with tab3:
    st.write("Ø¨ÙŠØ§Ù†Ø§ØªÙƒ Ø§Ù„ØµÙˆØªÙŠØ© Ø¢Ù…Ù†Ø© ÙˆÙ…Ø¹Ø§Ù„Ø¬ØªÙ‡Ø§ ØªØªÙ… Ù„Ø­Ø¸ÙŠØ§Ù‹ ÙˆÙ„Ø§ ÙŠØªÙ… ØªØ®Ø²ÙŠÙ†Ù‡Ø§.")

# ØªØ°ÙŠÙŠÙ„ Ø§Ù„ØµÙØ­Ø©
st.markdown("---")
st.caption("Â© 2026 Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø­Ù‚ÙˆÙ‚ Ù…Ø­ÙÙˆØ¸Ø© Ù„Ù€ Ø±Ø§Ù†ÙŠÙ‡Ø§Ù† Ù„Ø·ÙÙŠ | ØªØ·Ø¨ÙŠÙ‚ Speechify AI")
